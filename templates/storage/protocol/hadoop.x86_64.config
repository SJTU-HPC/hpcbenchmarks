[SERVER]
11.11.11.11

[DOWNLOAD]
hadoop/3.3.5 https://dlcdn.apache.org/hadoop/common/hadoop-3.3.5/hadoop-3.3.5.tar.gz

[DEPENDENCY]
mkdir -p $HPCbench_ROOT/benchmark/storage/protocol/hadoop_data
mkdir -p $HPCbench_ROOT/benchmark/storage/protocol/hadoop
mkdir -p $HPCbench_ROOT/result/storage/protocol/hadoop
tar -xzf $HPCbench_DOWNLOAD/hadoop-3.3.5.tar.gz -C $HPCbench_ROOT/benchmark/storage/protocol/hadoop
cd $HPCbench_ROOT/benchmark/storage/protocol/hadoop/hadoop-3.3.5
## 配置JAVA路径、HADOOP路径
## vim etc/hadoop/hadoop-env.sh
echo "export JAVA_HOME="/usr"" >> etc/hadoop/hadoop-env.sh
echo "export HADOOP_HOME="$HPCbench_ROOT/benchmark/storage/protocol/hadoop/hadoop-3.3.5"" >> etc/hadoop/hadoop-env.sh
export HADOOP_HOME=$HPCbench_ROOT/benchmark/storage/protocol/hadoop/hadoop-3.3.5
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

## 配置hadoop访问ip和数据存储目录
cat > etc/hadoop/core-site.xml << \EOF
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:8020</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>{{ HADOOP_DATA }}</value>
  </property>
</configuration>
EOF

## 配置hdfs复制数
cat > etc/hadoop/hdfs-site.xml << \EOF
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
EOF
# 3. 启动
hdfs namenode -format
hadoop-daemon.sh start namenode
hadoop-daemon.sh start datanode

[ENV]
export HADOOP_HOME=$HPCbench_ROOT/benchmark/storage/protocol/hadoop/hadoop-3.3.5
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export RESULT_DIR=$HPCbench_ROOT/result/storage/protocol/hadoop

[APP]
app_name = hadoop
build_dir = $HADOOP_HOME
binary_dir = $HADOOP_HOME
case_dir = $HADOOP_HOME

[BUILD]

[CLEAN]

[RUN]
binary = hadoop
run = echo
nodes = 1


[BATCH]
for i in 1 2 4 8 16; do
    hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.5-tests.jar TestDFSIO -write -nrFiles $i -fileSize 1GB -resFile $RESULT_DIR/hdfs_write.log
    hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.5-tests.jar TestDFSIO -read -nrFiles $i -fileSize 1GB -resFile $RESULT_DIR/hdfs_read.log
done
